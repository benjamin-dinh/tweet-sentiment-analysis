{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQ+418HewTapnCW/TuHNIv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjamin-dinh/tweet-sentiment-analysis/blob/main/tweet_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBrsSyU5yQkK"
      },
      "source": [
        "# **Sentiment Analysis of Airline Tweets**\n",
        "\n",
        "--- \n",
        "\n",
        "Labeled American airline tweets based on polarity of opinion: positive, neutral, and negative\n",
        "\n",
        "Utilized Natural Language Toolkit (nltk) to tokenize, lemmatize, and determine word frequency\n",
        "\n",
        "Used TF-IDF, term frequencyâ€“inverse document frequency, to calculate word importance\n",
        "\n",
        "Classified tweets using logistic regression\n",
        "\n",
        "The data set comes from https://raw.githubusercontent.com/lkyin/ECS189L/main/Tweets.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEvRn-x9yV_b"
      },
      "source": [
        "##  ***Top 10 Most Frequently Used Words in Each Sentiment Group***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLmKdRw63gyw"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/lkyin/ECS189L/main/Tweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47E9e1MT-AUS"
      },
      "source": [
        "### Clean and Tokenize Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxCDlFyD85aH",
        "outputId": "a1242e7f-8cc4-40a9-925e-cca45b166a47"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stopwords.words('english')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Add a column to df with only tokenized text\n",
        "def clean(df):\n",
        "  clean_text = []\n",
        "  clean_joined_text = []\n",
        "  for index, row in df.iterrows():\n",
        "    # Strip of Punctuation, Emojis, Hyperlinks, etc\n",
        "    text = row['text'].split(' ')\n",
        "    for w in text:\n",
        "      if (w!='' and (w[0]=='@' or w[0]=='#')):\n",
        "        text.remove(w)\n",
        "    newtext = ' '.join(text)\n",
        "    word_tokens = word_tokenize(newtext)\n",
        "    # Tokenize\n",
        "    temp = [w.lower() for w in word_tokens if not w in stop_words and w.isalpha() and not w=='http' and not w=='https' and not len(w)<=1]\n",
        "    tokentext = ' '.join(temp)\n",
        "    clean_text.append(temp)\n",
        "    clean_joined_text.append(tokentext)\n",
        "  df['clean_text'] = clean_text\n",
        "  df['clean_joined_text'] = clean_joined_text\n",
        "  return df\n",
        "\n",
        "df = clean(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsUkbfjq4-xf"
      },
      "source": [
        "### Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giLo5Eoe7mkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b717fe9-29b0-4556-efc1-f5a38e4aa72f"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(text):\n",
        "  words = []\n",
        "  for index, row in enumerate(text):\n",
        "    words += row\n",
        "  for i,word in enumerate(words):\n",
        "    words[i] = lemmatizer.lemmatize(word)\n",
        "  return words\n",
        "\n",
        "neutral_df = df.loc[df['airline_sentiment'] == 'neutral']\n",
        "negative_df = df.loc[df['airline_sentiment'] == 'negative']\n",
        "positive_df = df.loc[df['airline_sentiment'] == 'positive']\n",
        "\n",
        "neutral_words = lemmatize(neutral_df['clean_text'])\n",
        "negative_words = lemmatize(negative_df['clean_text'])\n",
        "positive_words = lemmatize(positive_df['clean_text'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsiTeARQNzyH"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx0KLFhBNyzg",
        "outputId": "222103b1-be94-4959-9492-46f47225fcc2"
      },
      "source": [
        "def count_words(words):\n",
        "  freq = nltk.FreqDist(words)\n",
        "  for word, frequency in freq.most_common(10):\n",
        "      print(u'{}:{}'.format(word, frequency))\n",
        "  print('\\n')\n",
        "\n",
        "print(\"Neutral Frequency\")\n",
        "count_words(neutral_words)\n",
        "print(\"Negative Frequency\")\n",
        "count_words(negative_words)\n",
        "print(\"Positive Frequency\")\n",
        "count_words(positive_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neutral Frequency\n",
            "flight:768\n",
            "get:241\n",
            "need:180\n",
            "please:180\n",
            "help:164\n",
            "thanks:154\n",
            "dm:129\n",
            "would:127\n",
            "ticket:112\n",
            "tomorrow:107\n",
            "\n",
            "\n",
            "Negative Frequency\n",
            "flight:3326\n",
            "hour:1083\n",
            "get:1013\n",
            "cancelled:914\n",
            "customer:771\n",
            "service:761\n",
            "time:730\n",
            "bag:656\n",
            "hold:611\n",
            "help:600\n",
            "\n",
            "\n",
            "Positive Frequency\n",
            "thanks:606\n",
            "thank:452\n",
            "flight:432\n",
            "great:235\n",
            "service:163\n",
            "love:130\n",
            "customer:123\n",
            "guy:122\n",
            "get:120\n",
            "you:118\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvQLP8b6UZfN"
      },
      "source": [
        "##  ***Classification Model Using Logistic Regression***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ly7YfU_DEQw"
      },
      "source": [
        "### Select Dependent Variable and Independent Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R9Jo9guAA7G"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tweets = df['clean_joined_text'].to_list()\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(tweets)\n",
        "Y = df['airline_sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w3ZcNV6DLy-"
      },
      "source": [
        "### Split Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PwgcSsj9xu8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIQql7CxONCV"
      },
      "source": [
        "### Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YNfF4MPOMTz"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(max_iter=100000)\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZty07jPDQie"
      },
      "source": [
        "### Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BLYAFwL-C82t",
        "outputId": "a7b1a146-22f7-45f7-a648-14c9f5510f07"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(Y_test, Y_pred, output_dict = True)\n",
        "pd.DataFrame(report).transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.803242</td>\n",
              "      <td>0.944415</td>\n",
              "      <td>0.868127</td>\n",
              "      <td>1889.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.671958</td>\n",
              "      <td>0.437931</td>\n",
              "      <td>0.530271</td>\n",
              "      <td>580.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.823708</td>\n",
              "      <td>0.590414</td>\n",
              "      <td>0.687817</td>\n",
              "      <td>459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.788593</td>\n",
              "      <td>0.788593</td>\n",
              "      <td>0.788593</td>\n",
              "      <td>0.788593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.766303</td>\n",
              "      <td>0.657587</td>\n",
              "      <td>0.695405</td>\n",
              "      <td>2928.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.780444</td>\n",
              "      <td>0.788593</td>\n",
              "      <td>0.772936</td>\n",
              "      <td>2928.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision    recall  f1-score      support\n",
              "negative       0.803242  0.944415  0.868127  1889.000000\n",
              "neutral        0.671958  0.437931  0.530271   580.000000\n",
              "positive       0.823708  0.590414  0.687817   459.000000\n",
              "accuracy       0.788593  0.788593  0.788593     0.788593\n",
              "macro avg      0.766303  0.657587  0.695405  2928.000000\n",
              "weighted avg   0.780444  0.788593  0.772936  2928.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8kOX3U1Dmiy"
      },
      "source": [
        "##  ***Airline Rankings Based on Sentiment***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvIOBXVZIg8G"
      },
      "source": [
        "### Count Number of Positive and Negative Tweets Per Airline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4ZZSqLBEgDa"
      },
      "source": [
        "sentiment_df = df.groupby([\"airline\", \"airline_sentiment\"]).size().reset_index(name=\"count\")\n",
        "airlinecount_df = df.groupby([\"airline\"]).size().reset_index(name=\"total\")\n",
        "airlinecount_df = pd.DataFrame(np.repeat(airlinecount_df.values,3,axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB4HjuFvIpxk"
      },
      "source": [
        "### Calculate Fraction of Positive and Negative Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "tsRvlhiIF-40",
        "outputId": "15030a6b-f3ac-4d02-c7a9-af9d1e810d0b"
      },
      "source": [
        "sentiment_df['fraction'] = sentiment_df['count']/airlinecount_df[1]\n",
        "sentiment_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>count</th>\n",
              "      <th>fraction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>American</td>\n",
              "      <td>negative</td>\n",
              "      <td>1960</td>\n",
              "      <td>0.710402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>American</td>\n",
              "      <td>neutral</td>\n",
              "      <td>463</td>\n",
              "      <td>0.167814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>American</td>\n",
              "      <td>positive</td>\n",
              "      <td>336</td>\n",
              "      <td>0.121783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Delta</td>\n",
              "      <td>negative</td>\n",
              "      <td>955</td>\n",
              "      <td>0.429793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Delta</td>\n",
              "      <td>neutral</td>\n",
              "      <td>723</td>\n",
              "      <td>0.325383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Delta</td>\n",
              "      <td>positive</td>\n",
              "      <td>544</td>\n",
              "      <td>0.244824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Southwest</td>\n",
              "      <td>negative</td>\n",
              "      <td>1186</td>\n",
              "      <td>0.490083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Southwest</td>\n",
              "      <td>neutral</td>\n",
              "      <td>664</td>\n",
              "      <td>0.27438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Southwest</td>\n",
              "      <td>positive</td>\n",
              "      <td>570</td>\n",
              "      <td>0.235537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>US Airways</td>\n",
              "      <td>negative</td>\n",
              "      <td>2263</td>\n",
              "      <td>0.776862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>US Airways</td>\n",
              "      <td>neutral</td>\n",
              "      <td>381</td>\n",
              "      <td>0.130793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>US Airways</td>\n",
              "      <td>positive</td>\n",
              "      <td>269</td>\n",
              "      <td>0.0923447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>United</td>\n",
              "      <td>negative</td>\n",
              "      <td>2633</td>\n",
              "      <td>0.688906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>United</td>\n",
              "      <td>neutral</td>\n",
              "      <td>697</td>\n",
              "      <td>0.182365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>United</td>\n",
              "      <td>positive</td>\n",
              "      <td>492</td>\n",
              "      <td>0.128728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Virgin America</td>\n",
              "      <td>negative</td>\n",
              "      <td>181</td>\n",
              "      <td>0.359127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Virgin America</td>\n",
              "      <td>neutral</td>\n",
              "      <td>171</td>\n",
              "      <td>0.339286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Virgin America</td>\n",
              "      <td>positive</td>\n",
              "      <td>152</td>\n",
              "      <td>0.301587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           airline airline_sentiment  count   fraction\n",
              "0         American          negative   1960   0.710402\n",
              "1         American           neutral    463   0.167814\n",
              "2         American          positive    336   0.121783\n",
              "3            Delta          negative    955   0.429793\n",
              "4            Delta           neutral    723   0.325383\n",
              "5            Delta          positive    544   0.244824\n",
              "6        Southwest          negative   1186   0.490083\n",
              "7        Southwest           neutral    664    0.27438\n",
              "8        Southwest          positive    570   0.235537\n",
              "9       US Airways          negative   2263   0.776862\n",
              "10      US Airways           neutral    381   0.130793\n",
              "11      US Airways          positive    269  0.0923447\n",
              "12          United          negative   2633   0.688906\n",
              "13          United           neutral    697   0.182365\n",
              "14          United          positive    492   0.128728\n",
              "15  Virgin America          negative    181   0.359127\n",
              "16  Virgin America           neutral    171   0.339286\n",
              "17  Virgin America          positive    152   0.301587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvHE6M2oIwMb"
      },
      "source": [
        "### Results\n",
        "\n",
        "*Top 3 Airlines in Terms of Fraction of Positive Tweets*\n",
        "1. Virgin America\n",
        "2. Delta\n",
        "3. Southwest\n",
        "\n",
        "*Top 3 Airlines in Terms of Fraction Negative Tweets*\n",
        "1. US Airways\n",
        "2. American\n",
        "3. United"
      ]
    }
  ]
}